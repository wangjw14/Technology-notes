# some video notes

## 黄仁勋与OpenAI首席科学家Ilya Sutskever的炉边谈话 4K 中文字幕

- 模型训练的本质是压缩数据。
- 只要对于下一个token预测的足够好，就可以得到表征，就可以对数据进行足够的压缩。
- 最开始使用的是lstm去做NSP，直到遇到了transfomers，然后就有了GPT-1
- OpenAI一开始就知道模型越大越好，但是需要找到如何进行scaling的方法
- 强化学习是另一个很重要的分支（GPT提供基座，RL提供RLHF，结合产生了chatGPT）
- 语言是对世界的映射，因此语言模型就是世界模型。因此，对于下一个token预测的越准确，还原度越高，在这个过程中得到的世界的分辨率就越高。这就是预训练阶段需要做的事情。
- 对齐，使得模型更精确和可靠
- 为什么多模态很重要：1、视觉对于模型很重要，世界是视觉化的，大脑皮层有1/3区域用于视觉。2、从图像中可以学到世界更多的知识，有些知识无法仅从语言中学习得到（增加了新的feature）。（人类一生会听到10亿个词，10亿秒是30年。）
- AI的可信任性，对于应用而言，至关重要。例如：
  - 摘要中，确保没有丢失任何的重要信息。
  - 模型是否清楚地遵循了用户的意图，也就是说，当信息不足够时，需要取询问更多信息，当不知道时，要表明不知道。


## InstructGPT
### 导言
- LM的目标函数和实际的目标不一致。LM的目标函数是预测next token，而实际上人们希望模型遵照指令安全的输出。

- 主要的结论
  - 标注人员认为instructGPT的结果比GPT3的结果要好很多（significantly better）
  - 在真实性上，显著好于GPT3
  - 在有毒性上，显著好于GPT3。但是在偏见上，没有显著提升。比如政客都是男的。
  - 在做RLHF的时候，把原始的目标函数一起放进来。使得在其他任务上效果没有下降很多。
  - 模型有一定的泛化性。可以在见到比较少的标注数据上，也有不错的性能。
  - 模型可能会犯一些简单的错误

- 有reward model的好处
  - 生成一个好的数据，成本要高于，对已有的数据进行排序。
  - 数据标注的成本可以更低，可以更快速的得到更多标注数据。


### 方法
- 3个数据集
  - SFT 数据集，13k
  - RM 数据集，33k
  - PPO 数据集，31k
- 标注时候的一些细节
  - 标注人员首先注意有用性
  - 评估人员首先注意真实性和安全性
- 模型训练
  - SFT训练了16个epoch
  - RM只有6B，去除最后一层的unembedding layer，输入prompt和response，输出一个标量值。
  - 
  















