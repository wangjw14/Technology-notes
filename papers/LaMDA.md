# LaMDA

## 摘要

- LaMDA：Language Models for Dialog Applications，针对对话应用的语言模型。是一系列模型，最大137B，训练预料1.56T words。
- 单独 scaling 可以提升质量，但是无法解决安全性问题和事实性问题。
- 使用标注数据进行微调，并且让模型可以咨询外部数据，可以在上述2个问题上取得显著改善。
  - 通过少量标注数据，训练一个分类器，过滤候选数据，可以大幅改善模型的安全性问题。
  - 通过咨询外部知识数据，比如信息检索系统、翻译器、计算器等，可以大幅改善事实性问题。
- 探索了 LaMDA 在教育和内容推荐方面的应用，并分析了有效性和角色一致性。



## 1 引言

- Scaling laws 同样适用于对话模型。

- LaMDA 使用一个单独模型来完成多个任务，包括：基于外部知识库生成候选回答，用安全过滤器过滤回答，重新排序得到最高质量的回答。

- 主要评价指标：质量(quality)、安全性(safety)、真实性(groundedness)

  - 质量(quality) ：合理性、特异性、趣味性。人工标注 -> 训练模型 -> 对候选回复重新排序。
  - 安全性(safety)：减少模型生成不安全回复的数量。人工标注 -> 训练模型 -> 过滤。
  - 真实性(groundedness)：让模型产生基于已知源的应答。让模型模拟人查阅资料的行为。
  - scaling 可以提升质量，但是无法解决安全性和真实性问题
  - scaling + fine-tuning 可以在三个方面均有提升，尽管在安全性和真实性方面，离人工还有差距

  

## 2 相关工作

- 越来越多的文献表明，使用信息检索可以改善真实性问题
- 更多的文献聚焦在开放域的问答，而不是对话系统
- 通过将问答系统拆分为推理单元和回复生成器，可以提升问答系统的准确率。类似本文中的 “Base” 和 “Research” 模型
- 本文中使用了人工评估，对模型进行打分。
- 采用了5个指标，对模型进行评估：sensibleness, specificity, interestingness, safety, and groundedness



## 3 预训练

- 和其他的对话模型不同，也在大量的网络文本上进行了预训练，在微调之前，可以当成一个普通的语言模型
- 预训练数据：2.97B文档，1.12B 个对话，13.39B 对话话语，一共1.56T的words。其中90%是英语，使用 SentencePiece 将其分为 2.81T 的 BPE tokens。词表大小为 32K tokens。

- 模型结构：Decoder only Transformer。
- 模型参数量：137B的非 embedding 参数。64 layers, d_model = 8192, dff = 65536, h = 128, dk = dv = 128。
- 预训练：1024 块 TPU-v3，训练57.7天。batch size 256K。使用了 Lingvo 框架，速度达到 123 TFLOPS/sec， 56.5% FLOPS 利用率。
- 采样策略：使用 top-k (k=40) 的采样策略，没有使用 temperature 参数，先得到 16 个独立的候选输出。然后根据 log- likelihood 和长度选择最优的候选输出。



## 4 评估

### 4.1 基础评估指标：质量、安全和真实性

- 人工打 0/1 分
- 质量：SSI 是三者的均分（Sensibleness, Specificity, Interestingness）
- 安全：
- 真实性：

### 4.2 角色相关指标：

- 有用性和角色一致性



## 5 微调数据

- 质量：
  - 训练集：6400 dialogs with 121K turns。每次对话持续 14-30 turns。每轮对话，会被5个不同的众包人员进行标注，最少要有3个标注人员标注认为和合格才可以。
  - 测试集：Mini-Turing Benchmark (MTB) dataset。1477 dialogs with up to 3 dialog turns。标注方法同训练集。
- 安全性
  - 训练集：8K dialogs with 48K turns。每次对话持续 5-10 turns。让众包人员，和模型对话，采用3种不同的方式：(a) 自然形式的互动，(b) 涉及敏感话题的互动，以及 (c) 带有敌意，根据安全目标尝试破坏模型。至少3个众包人员中的2个，认为没有违反安全规则，则会认为是符合安全规则。
  - 测试集：1166 dialogs with 1458 turns。标注方法同训练集。
- 真实性
  - 训练集：4K dialogs with 40K turns。让对话朝着寻求信息（information-seeking）的方向进行互动。如果3个众包人员都认为陈述时正确的，则认为是一个常识，不再需要在外部知识中进行确认。如果需要查询外部知识，需要记录 query 和 url。
  - 测试集：784 turns的数据，标注方法同训练集。
- 人工针对这些问题，生成了一些回复。也使用了上述的评估指标和方法进行评估。

## 6 微调

### 6.1 判别式和生成式混合微调

- 一个模型可以同时完成回复生成，以及对回复质量的判断。
  - 生成式微调：<上下文> <标识符> <回复>
  - 判别式微调：<上下文> <标识符> <回复> <属性名> <打分>
- 首先，微调模型对质量和安全性进行打分。安全分数低于阈值会被过滤，其余的会按照质量分数进行排序，打分的时候，sensible的权重是其他两项的3倍。
- 判别式模型同样被用于过滤数据。2.5M的数据，过滤之后，得到了800K数据。这部分数据被用于微调模型。在安全性和质量方面得到了巨大的提升。

### 6.2 使用外部信息检索系统

- 工具集：信息检索系统、计算器、翻译器
- 输入：str；输出：list of str
- 











