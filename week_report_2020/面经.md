## 面经

- 为什么LSTM比RNN好

  - LSTM如何来避免梯度弥散和梯度爆炸？ - Towser的回答 - 知乎 https://www.zhihu.com/question/34878706/answer/665429718

- batch size怎么设置？

  - 并不是越大越好。小的batch size可以带来更多的噪声，防止陷入局部最小值（鞍点），但是训练时间长。大的batch size可以缩短训练时间（更好的并行）。
  - 怎么选取训练神经网络时的Batch size? - 夕小瑶的回答-知乎 https://www.zhihu.com/question/61607442/answer/204525634
  - 怎么选取训练神经网络时的Batch size? - Matt的回答 - 知乎 https://www.zhihu.com/question/61607442/answer/192204021
  - 如何设置合适的 batch 大小收获 4 倍加速 & 更好的泛化效果：https://www.leiphone.com/news/201911/XthpCSNTEk03RaPI.html
  - 英文原文：https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf

- learning rate 怎么设置？

  - pytorch中有多种学习率设置方式：
    - 有序调整：依一定规律有序进行调整，这一类是最常用的，分别是等间隔下降(Step)，按需设定下降间隔(MultiStep)，指数下降(Exponential)和CosineAnnealing。这四种方法的调整时机都是人为可控的，也是训练时常用到的。
    - 自适应调整：依训练状况伺机调整，这就是ReduceLROnPlateau方法。该法通过监测某一指标的变化情况，当该指标不再怎么变化的时候，就是调整学习率的时机，因而属于自适应的调整。
    - 自定义调整：Lambda。Lambda方法提供的调整策略十分灵活，我们可以为不同的层设定不同的学习率调整方法，这在fine-tune中十分有用，我们不仅可为不同的层设定不同的学习率，还可以为其设定不同的学习率调整策略，简直不能更棒！
  - fastai有一个工具可以根据lr-loss图，选取一个较好的leraning rate。
  - PyTorch 学习笔记（八）：PyTorch的六个学习率调整方法 - 余霆嵩的文章 - 知乎 https://zhuanlan.zhihu.com/p/69411064
  - [译]如何找到一个好的学习率(learning rate) - 陈志远的文章 - 知乎 https://zhuanlan.zhihu.com/p/50499794
  - 上面的英文原文：https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html
  - 如何找到最优学习率 - Sherlock的文章 - 知乎 https://zhuanlan.zhihu.com/p/31424275
  - [机器之心]机器学习算法如何调参？一份神经网络学习速率设置指南 https://www.jiqizhixin.com/articles/nn-learning-rate

- 深度学习中batch size 和 learning rate有什么关系？
  $$
  \text { new_learningrate }=\text { old_learningrate } * \sqrt{\text {new_batchsize} / \text {old_batchsize}}
  $$

  - https://blog.csdn.net/qq_27261889/article/details/103120985 
  - https://arxiv.org/pdf/1404.5997.pdf 

- 损失函数：
  
- 深度学习-Loss函数 - Evan的文章 - 知乎 https://zhuanlan.zhihu.com/p/97698386
  - PyTorch 学习笔记（六）：PyTorch的十八个损失函数 - 余霆嵩的文章 - 知乎 https://zhuanlan.zhihu.com/p/61379965
  
- python装饰器
  - 如何理解Python装饰器？ - 刘志军的回答 - 知乎 https://www.zhihu.com/question/26930016/answer/99243411
  - 如何理解Python装饰器？ - NET.Dzreal的回答 - 知乎 https://www.zhihu.com/question/26930016/answer/1047233982

- 参数初始化
  - 权重/参数初始化 - G-kdom的文章 - 知乎 https://zhuanlan.zhihu.com/p/72374385
  - https://blog.csdn.net/u012328159/article/details/80025785

- 数据shuffle和position embedding怎么取舍
  - 部分shuffle？
- 通过广告点击序列去预测下一个广告：RNN，GPT
- 不同的embedding的组合方式：拼接、相加（共享权重的拼接）

- 不平衡数据的处理：
  - 极端类别不平衡数据下的分类问题S02：问题概述，模型选择及人生经验 - 刘芷宁的文章 - 知乎 https://zhuanlan.zhihu.com/p/66373943

- 5局3胜还是3局2胜？
  - 从概率角度，5局3胜和3局2胜，哪个胜算更大？ - 罗承成的文章 - 知乎 https://zhuanlan.zhihu.com/p/61655460
  - 【概率】甲乙射击比赛，单局甲胜率0.6，3局2胜和5局3胜两种赛制甲如何选择？无限多局，甲获胜概率？ https://blog.csdn.net/weixin_41888257/article/details/108371738

- 线性回归为何用均方差
  - 欧几里得距离
  - 误差服从均值为0，方差保持不变的正态分布，然后使用似然函数去估计
  - https://blog.csdn.net/dpengwang/article/details/96845324

- 迭代器生成器差别
  - 如何更好地理解Python迭代器和生成器？ - 赖明星的回答 - 知乎 https://www.zhihu.com/question/20829330/answer/133606850
- 正则表达式
  - python 正则表达式中search/match/findall区别 https://blog.csdn.net/qq_43220632/article/details/98336851 
- 防止过拟合
  - 数据增强、合适（简单）的模型、正则、dropout、early stopping、模型集成
  - 机器学习中用来防止过拟合的方法有哪些？ - fly qq的回答 - 知乎 https://www.zhihu.com/question/59201590/answer/167392763



## 不太会

- FM是否也能起到自动特征选的作用，为什么
- 非线性分类算法有哪些
- 如何判断一个算法是线性的还是非线性的
- 一个用户在搜索框输入query之后，如何知道他是否是在找视频
- 如何计算一个微博账户的权威分数
- 如果用数组实现，数组初始容量为n，每次push到容量上限之后都扩容到原来的 两倍，现在push进去m个数，m远大于n，求相比于m的时间复杂度

- python的动态数组是如何实现的
- 为什么softmax要和cross entropy一起计算？
- x, y是独立的随机变量，方差期望已知，那么如何求 xy 的方差

## 大数据问题

- 如果有很大的文件，怎么统计里面出现的各个单词的数量(1):百度 
- topK三种解法(3):百度、美团 
  - 数据结构和算法之TOP K算法 https://blog.csdn.net/zy15112342449/article/details/102765137
  - 算法必学：经典的 Top K 问题 https://juejin.im/entry/6844903774004183047
- 现在有一亿个样本，如何找到单词最相似的?(1):百度 
- 有两张表，第一张表有n个专有名词，比如今日头条、抖音等，第二张表 有m条query，比如今日头条是怎样的应用、有多少人喜欢刷抖音等，如 何统计表1中所有名词在表2中出现的频次(1):头条 
- 10亿个32位正整数，求不同值，只给1GB内存(1):腾讯



## 再巩固下

- 逻辑回归推导
- 推导逻辑回归的梯度
- 权值初始化方式对LR的收敛有影响吗?
- svm损失函数推导
- ROC、AUC
- 数据不平衡的情况
- 上采样有哪些方式
- 针对高维数据，如何做特征选择?
- SoftMax + CrossEntropy的反向梯度求导
- 交叉熵loss公式
  - 损失函数 - 交叉熵损失函数 - 飞鱼Talk的文章 - 知乎 https://zhuanlan.zhihu.com/p/35709485

- CRF讲一下



## 面经里的算法题

- #### [3. 无重复字符的最长子串](https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/)

- #### [76. 最小覆盖子串](https://leetcode-cn.com/problems/minimum-window-substring/)

- #### [324. 摆动排序 II](https://leetcode-cn.com/problems/wiggle-sort-ii/)

- 最快速度最小空间求一个数组的第k小

- 



# Plan of next week

- 


