# LLaMA

### 摘要

- LLaMA是一个系列模型，模型参数量从7B到65B。
- 在大部分的任务上，LLaMA-13B强于GPT-3(175B)
- LLaMA-65B的性能，可以和最好的LM相媲美，如Chinchilla-70B 和 PaLM-540B



### 引言

- 一般而言，模型越大，效果越好。然而有文献指出，当给定计算量的预算之后，最好的性能，并不是最大的模型，而是在一个小模型上用更多的数据进行训练。

- 