# LaMDA

## 摘要

- LaMDA：针对对话应用的语言模型。是一系列模型，最大137B，训练预料1.56T words。
- 单独 scaling 可以提升质量，但是无法解决安全性问题和事实性问题。
- 使用标注数据进行微调，并且让模型可以咨询外部数据，可以在上述2个问题上取得显著改善。
  - 通过少量标注数据，训练一个分类器，过滤候选数据，可以大幅改善模型的安全性问题。
  - 通过咨询外部知识数据，比如信息检索系统、翻译器、计算器等，可以大幅改善事实性问题。
- 探索了 LaMDA 在教育和内容推荐方面的应用，并分析了有效性和角色一致性。



## 引言

- Scaling laws 同样适用于对话模型。

- LaMDA 使用一个单独模型来完成多个任务，包括：基于外部知识库生成候选回复，将回复用安全过滤器过滤，重新排序得到最高质量的回答。

- 主要评价指标：质量(quality)、安全性(safety)、真实性(groundedness)

  - 质量(quality) ：合理性、特异性、趣味性。人工标注 -> 训练模型 -> 对候选回复重新排序。
  - 安全性(safety)：减少模型生成不安全回复的数量。人工标注 -> 训练模型 -> 过滤。
  - 真实性(groundedness)：让模型产生基于已知源的应答。让模型模拟人查阅资料的行为。
  - scaling 可以提升质量，但是无法解决安全性和真实性问题
  - scaling + fine-tuning 可以在三个方面均有提升，尽管在安全性和真实性方面，离人工还有差距

  

## 相关工作

- 越来越多的文献表明，使用信息检索可以改善真实性问题
- 更多的文献聚焦在开放域的问答，而不是对话系统
- 通过将问答系统拆分为推理单元和回复生成器，可以提升问答系统的准确率











